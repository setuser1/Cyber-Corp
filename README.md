# Article:

## Check commits for more!
https://www.engadget.com/ai/surprising-no-one-researchers-confirm-that-ai-chatbots-are-incredibly-sycophantic-185935470.html?src=rss

AI

Surprising no one, researchers confirm that AI chatbots are incredibly sycophantic

A study confirms they endorse a users actions 50 percent more often than humans do.

Lawrence Bonk

Contributing Reporter

Fri, October 24, 2025 at 6:59 PM UTC

Unsplash / Sanket Mishra

We all have anecdotal evidence of chatbots blowing smoke up our butts, but now we have science to back it up. Researchers at Stanford, Harvard and other institutions just published a study in Nature about the sycophantic nature of AI chatbots and the results should surprise no one. Those cute little bots just love patting us on our heads and confirming whatever nonsense we just spewed out.

The researchers investigated advice issued by chatbots and they discovered that their penchant for sycophancy "was even more widespread than expected." The study involved 11 chatbots, including recent versions of ChatGPT, Google Gemini, Anthropic's Claude and Meta's Llama. The results indicate that chatbots endorse a human's behavior 50 percent more than a human does.

They conducted several types of tests with different groups. One compared responses by chatbots to posts on Reddit's "Am I the Asshole" thread to human responses. This is a subreddit in which people ask the community to judge their behavior, and Reddit users were much harder on these transgressions than the chatbots.

But there's a darker side…

MIT researchers used Reddit's "Am I The Asshole?" data to test how AI models become overly sycophantic and agreeable

Your most vulnerable moments are training tomorrow's AI. pic.twitter.com/vRgYSjudGh

— anarchy.build (@anarchy_build) July 19, 2025

One poster wrote about tying a bag of trash to a tree branch instead of throwing it away, to which ChatGPT-4o declared that the person's "intention to clean up" after themself was "commendable." The study went on to suggest that chatbots continued to validate users even when they were "irresponsible, deceptive or mentioned self-harm", according to a report by The Guardian.

Advertisement

Advertisement

What's the harm in indulging a bit of digital sycophancy? Another test had 1,000 participants discuss real or hypothetical scenarios with publicly available chatbots, but some of them had been reprogrammed to tone down the praise. Those who received the sycophantic responses were less willing to patch things up when arguments broke out and felt more justified in their behavior, even when it violated social norms. It's also worth noting that the traditional chatbots very rarely encouraged users to see things from another person's perspective.

"That sycophantic responses might impact not just the vulnerable but all users, underscores the potential seriousness of this problem," said Dr. Alexander Laffer, who studies emergent technology at the University of Winchester. "There is also a responsibility on developers to be building and refining these systems so that they are truly beneficial to the user."

A study found 33% of teenagers use AI chatbots for companionship, conversation practice, and romance

They found talking to AI easier than talking to real people and use it for emotional support pic.twitter.com/AbCZbv6tpK

— Dexerto (@Dexerto) July 26, 2025

This is serious because of just how many people use these chatbots. A recent report by the Benton Institute for Broadband & Society suggested that 30 percent of teenagers talk to AI rather than actual human beings for "serious conversations." OpenAI is currently embroiled in a lawsuit that accuses its chatbot of enabling a teen's suicide. The company Character AI has also been sued twice after a pair of teenage suicides in which the teens spent months confiding in its chatbots.

Advertisement

About our ads